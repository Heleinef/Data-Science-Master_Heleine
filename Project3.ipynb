{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWO9YekW5/yX/lsEhHxm41",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heleinef/Data-Science-Master_Heleine/blob/main/Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
        "\n",
        "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
        "\n",
        "How does the performance on the test set compare to the performance on the dev-test set?\n",
        "Is this what you'd expect?\n",
        "Source: Natural Language Processing with Python, exercise 6.10.2."
      ],
      "metadata": {
        "id": "6ttiYCTPDLOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data\n"
      ],
      "metadata": {
        "id": "Hpc3bMAAD_Ea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYKjgfX6AP7_",
        "outputId": "dcff360e-18bb-457c-a60f-83e224e8c9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import names\n",
        "import random\n",
        "\n",
        "nltk.download('names')\n",
        "\n",
        "# Load the names corpus\n",
        "names = [(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')]\n",
        "\n",
        "# Shuffle the names\n",
        "random.shuffle(names)\n",
        "\n",
        "# Split the data\n",
        "train_set = names[1000:]\n",
        "dev_test_set = names[500:1000]\n",
        "test_set = names[:500]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features Extraction"
      ],
      "metadata": {
        "id": "SzyZ6SE1DbXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "    return {\n",
        "        'last_letter': word[-1],\n",
        "        'last_two_letters': word[-2:],\n",
        "        'first_letter': word[0],\n",
        "        'length': len(word),\n",
        "        'vowel_count': sum(1 for letter in word if letter in 'aeiou')\n",
        "    }\n"
      ],
      "metadata": {
        "id": "lGylID_6DcaB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "uWBlYoD7EMy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import apply_features\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "train_set = apply_features(gender_features, train_set)\n",
        "dev_test_set = apply_features(gender_features, dev_test_set)\n",
        "test_set = apply_features(gender_features, test_set)\n",
        "\n",
        "# Naive Bayes Classifier\n",
        "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set)\n",
        "\n",
        "# Maximum Entropy Classifier\n",
        "me_classifier = MaxentClassifier.train(train_set, max_iter=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH_Kw3KVEWJF",
        "outputId": "0ec86241-ecde-42c7-8f3d-922e5f2e9769"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.371\n",
            "             2          -0.44557        0.779\n",
            "             3          -0.38528        0.804\n",
            "             4          -0.35610        0.808\n",
            "             5          -0.33946        0.809\n",
            "             6          -0.32886        0.811\n",
            "             7          -0.32158        0.813\n",
            "             8          -0.31631        0.814\n",
            "             9          -0.31231        0.815\n",
            "         Final          -0.30918        0.817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "vCkktccZEhGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.util import accuracy\n",
        "\n",
        "print(\"Naive Bayes Accuracy on Dev-Test Set:\", accuracy(nb_classifier, dev_test_set))\n",
        "print(\"Decision Tree Accuracy on Dev-Test Set:\", accuracy(dt_classifier, dev_test_set))\n",
        "print(\"Max Entropy Accuracy on Dev-Test Set:\", accuracy(me_classifier, dev_test_set))\n"
      ],
      "metadata": {
        "id": "-lMdOx20Evr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final evaluation on test set"
      ],
      "metadata": {
        "id": "Idjzf1ceEzJ2"
      }
    },
    {
      "source": [
        "from nltk.classify.util import accuracy # Import the accuracy function\n",
        "\n",
        "print(\"Naive Bayes Accuracy on Test Set:\", accuracy(nb_classifier, test_set))\n",
        "print(\"Decision Tree Accuracy on Test Set:\", accuracy(dt_classifier, test_set))\n",
        "print(\"Max Entropy Accuracy on Test Set:\", accuracy(me_classifier, test_set))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRkX3GYxFXXK",
        "outputId": "0d7c2847-c6de-4dd8-92c7-d3f58038169f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy on Test Set: 0.782\n",
            "Decision Tree Accuracy on Test Set: 0.746\n",
            "Max Entropy Accuracy on Test Set: 0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "**Performance Comparison:** Compare the accuracy of the models on the dev-test set and the test set.\n",
        "**Expectation**: Typically, the performance on the test set may be slightly lower than the dev-test set due to overfitting during the tuning process."
      ],
      "metadata": {
        "id": "tZwwklI8FTxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "The performance on the test set should be close to the dev-test set but might be slightly lower, which is expected due to the model's slight overfitting to the dev-test set. This exercise demonstrates the importance of having separate dev-test and test sets for tuning and final evaluation."
      ],
      "metadata": {
        "id": "1ibmauJ3GWd6"
      }
    }
  ]
}